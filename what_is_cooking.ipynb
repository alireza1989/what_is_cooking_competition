{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's cooking competiton\n",
    "\n",
    "**The competitions** asks to predict the category of a dish's cuisine given a list of its ingredients.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, we include the **recipe id**, **the type of cuisine**, and **the list of ingredients of each recipe** (of variable length). The data is stored in JSON format. \n",
    "\n",
    "#### An example of a recipe node in train.json:\n",
    "\n",
    "```json\n",
    " {\n",
    " \"id\": 24717,\n",
    " \"cuisine\": \"indian\",\n",
    " \"ingredients\": [\n",
    "     \"tumeric\",\n",
    "     \"vegetable stock\",\n",
    "     \"tomatoes\",\n",
    "     \"garam masala\",\n",
    "     \"naan\",\n",
    "     \"red lentils\",\n",
    "     \"red chili peppers\",\n",
    "     \"onions\",\n",
    "     \"spinach\",\n",
    "     \"sweet potatoes\"\n",
    " ]\n",
    " },\n",
    " ```\n",
    " \n",
    "In the test file **test.json**, the format of a recipe is the same as **train.json**, only *the cuisine type* is removed, <font color=red>as it is the target variable you are going to predict.</font>\n",
    "\n",
    "#### File descriptions:\n",
    "\n",
    "**train.json -** the training set containing recipes id, type of cuisine, and list of ingredients\n",
    "\n",
    "**test.json -** the test set containing recipes id, and list of ingredients\n",
    "\n",
    "**sample_submission.csv -** a sample submission file in the correct format\n",
    "In the dataset, we include the recipe id, the type of cuisine, and the list of ingredients of each recipe (of variable length). The data is stored in JSON format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include required libraries\n",
    "import os\n",
    "import sys\n",
    "import data_utils as du\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from files\n",
    "trainingData = du.readJson('./data/train.json')\n",
    "testData = du.readJson('./data/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring first few rows of each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TRAINING DATA:')\n",
    "trainingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TEST DATA:')\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Distribution map for ingredients and food types in thetraining set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredientsColumn = trainingData['ingredients']\n",
    "recipeType = trainingData['cuisine']\n",
    "\n",
    "ingredientsDist = du.dataDistributionMap(ingredientsColumn)\n",
    "cuisineDist = du.dataDistributionMap(recipeType)\n",
    "\n",
    "print ('Number of cuisines in the data set:',len(cuisineDist))\n",
    "print ('Number of ingredients in the data set:',len(ingredientsDist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and the data to be used as input of a Neural Network ase well as create training and dev data-set\n",
    "\n",
    "1. we need to create input vectors representing each **recipe** and output vectors representing a **cuisine type**.\n",
    "2. XYZ \n",
    "3. XYZ\n",
    "4. XYZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepre the input matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map of ingredients\n",
    "w2i, i2w = du.wordsToMap(list(ingredientsDist.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(len(recipe) for recipe in trainingData['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An input matrix with having the ingredients encoded for each recipe and zero padding.\n",
    "# Each row is a recipe in the training set and will be the input of the first layer of NN\n",
    "X = du.convertToInputMatrix(trainingData['ingredients'], w2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData['ingredients'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i2w[0],\"\\n\",i2w[1], \"\\n\",i2w[2], \"\\n\",i2w[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the expected output matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map of index to cuisine  nad cuisine to index\n",
    "c2i, i2c = du.wordsToMap(list(cuisineDist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = du.convertToOutputMatrix(trainingData['cuisine'], c2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData['cuisine'][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c2i['southern_us'], i2c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=65, activation='relu', kernel_initializer=\"uniform\"))\n",
    "model.add(Dense(44, activation='tanh', kernel_initializer=\"uniform\"))\n",
    "model.add(Dense(32, activation='tanh', kernel_initializer=\"uniform\"))\n",
    "model.add(Dense(32, activation='tanh', kernel_initializer=\"uniform\"))\n",
    "model.add(Dense(25, activation='tanh', kernel_initializer=\"uniform\"))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, epochs=120, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
